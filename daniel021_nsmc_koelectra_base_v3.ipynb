{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "daniel021_nsmc_koelectra_small_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2382432b8d33438891e022ac5643c8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_15f9c5e074ba42249b8d962eafc10192",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01c823605d0446648429b25afbf72136",
              "IPY_MODEL_3982936c3b9b41c8a13b257a698bee9e"
            ]
          }
        },
        "15f9c5e074ba42249b8d962eafc10192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01c823605d0446648429b25afbf72136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ca3142c393646f185e3ffe4acb32d17",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 263326,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 263326,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_745c3d56801143aa98675d7974c970d9"
          }
        },
        "3982936c3b9b41c8a13b257a698bee9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_165691f1510e45b2a92de59ef207bdac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 263k/263k [00:01&lt;00:00, 151kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01e46f5209764d8798f5e0ef4fa35e4f"
          }
        },
        "6ca3142c393646f185e3ffe4acb32d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "745c3d56801143aa98675d7974c970d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "165691f1510e45b2a92de59ef207bdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01e46f5209764d8798f5e0ef4fa35e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db60288eabbc495f81964904c68e8121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_022e14bb64354b9b80f1b9fcfdf136ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3571445f1d4499696bbcf2c0c3e0797",
              "IPY_MODEL_0a4614f43fcc4e6cbaf38ebf5b2d8b34"
            ]
          }
        },
        "022e14bb64354b9b80f1b9fcfdf136ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3571445f1d4499696bbcf2c0c3e0797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_806bda4ca36249f683e1df7919533bbd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 61,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 61,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9351ac08f12343cd8956eab711c35077"
          }
        },
        "0a4614f43fcc4e6cbaf38ebf5b2d8b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bce9faadd42e48b9bee69560538a6ecf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 61.0/61.0 [00:00&lt;00:00, 190B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a72a186fb1d54a818fa4f037d5ef852d"
          }
        },
        "806bda4ca36249f683e1df7919533bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9351ac08f12343cd8956eab711c35077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bce9faadd42e48b9bee69560538a6ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a72a186fb1d54a818fa4f037d5ef852d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4677dbd810db496290ee678121f27e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_889ae85fd6ef4a5cbdd6b7b3c97282d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b831611028c84ae58aeb8452a1ec3cd4",
              "IPY_MODEL_ed38334e4f364efd87b02794fc88fde9"
            ]
          }
        },
        "889ae85fd6ef4a5cbdd6b7b3c97282d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b831611028c84ae58aeb8452a1ec3cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_387493a93a13402b968b58b30524b831",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28673908e6ae408c8aa17e8f6aecee0b"
          }
        },
        "ed38334e4f364efd87b02794fc88fde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f23ee0740184754b12cdad37299487b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 467/467 [00:00&lt;00:00, 1.19kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4c15ba2ba2a4baea1e411eba1d7438a"
          }
        },
        "387493a93a13402b968b58b30524b831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28673908e6ae408c8aa17e8f6aecee0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f23ee0740184754b12cdad37299487b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4c15ba2ba2a4baea1e411eba1d7438a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbf18e171f3942958114ff90fbf18390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea15e7924ac44b028e3276d5eeca03e5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6d672432a044d12ad06f74dc6abc05b",
              "IPY_MODEL_e472dfe07d224634a39f6df6748ed6fe"
            ]
          }
        },
        "ea15e7924ac44b028e3276d5eeca03e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6d672432a044d12ad06f74dc6abc05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_87c805a1db7c40b0a0700d1641448f6d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 451776329,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 451776329,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd5c27139e39448fb633cfce68094f5a"
          }
        },
        "e472dfe07d224634a39f6df6748ed6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08de05aa296744218e4d895d8f264bb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 452M/452M [00:10&lt;00:00, 41.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0cba89c2e47948d5b873c210571d9b73"
          }
        },
        "87c805a1db7c40b0a0700d1641448f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd5c27139e39448fb633cfce68094f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08de05aa296744218e4d895d8f264bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0cba89c2e47948d5b873c210571d9b73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f4aed0f5a744403a955efe7902c9683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fe0c6e7615542af9747d9269f19de6e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b92b3bb6aee4106a57fc5aeb2e3a5de",
              "IPY_MODEL_108232f989f94a7fa3d67e7166b5498c"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MunJinSeo/MyProject/blob/master/daniel021_nsmc_koelectra_base_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdjLL9gvyVCR"
      },
      "source": [
        "# 한국어 KoELECTRA를_이용한_감정분석기_학습 (Pytorch + HuggingFace)\n",
        "# Colab 에서 개발 및 실행\n",
        "<br>\n",
        "\n",
        "## References 1\n",
        "- 김희규님의 \"HuggingFace KoElectra로 NSMC 감성분석 Fine-tuning해보기\"<br>\n",
        "https://heegyukim.medium.com/huggingface-koelectra%EB%A1%9C-nsmc-%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8%ED%95%99%EC%8A%B5%ED%95%98%EA%B8%B0-1a23a0c704af\n",
        "\n",
        "- 이지원님의 Github : nlp_emotion_classification <br>\n",
        "https://github.com/jiwonny/nlp_emotion_classification\n",
        "\n",
        "## 사용모델 KoELECTRA , ELECTRA\n",
        "- 한국어 : 박장원님의 KoElectra-small 사용<br>\n",
        "https://monologg.kr/2020/05/02/koelectra-part1/<br>\n",
        "https://github.com/monologg/KoELECTRA\n",
        "- 영어 : 구글 ELECTRA - small 사용<br>\n",
        "https://huggingface.co/google/electra-small-discriminator<br>\n",
        "https://github.com/google-research/electra\n",
        "\n",
        "## Dataset\n",
        "- 한국어 : 네이버 영화 리뷰 데이터셋<br>\n",
        "https://github.com/e9t/nsmc\n",
        "- 영어 : Freinds <br>\n",
        "http://doraemon.iis.sinica.edu.tw/emotionlines/\n",
        "\n",
        "## References 2\n",
        "- https://colab.research.google.com/drive/1tIf0Ugdqg4qT7gcxia3tL7und64Rv1dP\n",
        "- https://blog.naver.com/horajjan/221739630055\n",
        "<br>@@<br>\n",
        "- https://github.com/YongWookHa/kor-text-preprocess\n",
        "- https://github.com/likejazz/korean-sentence-splitter\n",
        "- https://github.com/lovit/soynlp\n",
        "<br>@@<br>\n",
        "- https://huggingface.co/transformers/training.html\n",
        "- https://tutorials.pytorch.kr/beginner/data_loading_tutorial.html\n",
        "- https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html\n",
        "- https://wikidocs.net/44249\n",
        "\n",
        "\n",
        "## 기타\n",
        "반드시 GPU로 실행 - Colab무료환경에서 1epoch 당 약 15~20분 소요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAi68f2lmB--"
      },
      "source": [
        "# 필요 lib 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc7P9wzHv0LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a91c3f-d700-4c1b-87a8-5f36b1d40975"
      },
      "source": [
        "# lib 설치\n",
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 17.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 14.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 13.1MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 15.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 13.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 13.1MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 11.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 11.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 11.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 11.7MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 11.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 11.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 11.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 11.7MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 11.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 11.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 11.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 11.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 11.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=3bdca4384482169ce5439965a982504b4eb687fbdec56496505cd05e1069a9f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emCAmYZwiDbH",
        "outputId": "e0a0d1fe-5d4b-48dd-f26e-24057286d88c"
      },
      "source": [
        "!pip install kss\r\n",
        "!pip install konlpy\r\n",
        "!pip install sentencepiece\r\n",
        "!pip install soynlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kss\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/bb/4772901b3b934ac204f32a0bd6fc0567871d8378f9bbc7dd5fd5e16c6ee7/kss-1.3.1.tar.gz\n",
            "Building wheels for collected packages: kss\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-1.3.1-cp36-cp36m-linux_x86_64.whl size=251533 sha256=d712bc496789659baa76fb3d6d9ae621fcf2e95415bd1466ee41b86577d579ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/98/d1/53f75f89925cd95779824778725ee3fa36e7aa55ed26ad54a8\n",
            "Successfully built kss\n",
            "Installing collected packages: kss\n",
            "Successfully installed kss-1.3.1\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.1MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: colorama, tweepy, JPype1, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n",
            "Collecting soynlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.19.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.0.0)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHgwtvRbdOUb"
      },
      "source": [
        "# (미사용) Colab TPU 사용을 위해 설치\r\n",
        "#--!pip install torch_xla\r\n",
        "#--#@param [\"1.5\" , \"20200325\", \"nightly\"]\r\n",
        "#VERSION = \"1.7\"\r\n",
        "#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\r\n",
        "#!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWfuBjAXmInF"
      },
      "source": [
        "# NSMC 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhX0Ze8DV3Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0e50a1-ddb1-40f5-c6df-da831dea73d4"
      },
      "source": [
        "#NSMC 데이터셋 다운로드\r\n",
        "\r\n",
        "#!git clone https://github.com/e9t/nsmc.git\r\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\r\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\r\n",
        "# ko_data.csv #별도 kaggle에서 받아서 사용 https://www.kaggle.com/c/korean-sa-competition-bdc101"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-19 22:09:11--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893335 (4.7M) [text/plain]\n",
            "Saving to: ‘ratings_test.txt’\n",
            "\n",
            "ratings_test.txt    100%[===================>]   4.67M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-12-19 22:09:12 (53.7 MB/s) - ‘ratings_test.txt’ saved [4893335/4893335]\n",
            "\n",
            "--2020-12-19 22:09:12--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14628807 (14M) [text/plain]\n",
            "Saving to: ‘ratings_train.txt’\n",
            "\n",
            "ratings_train.txt   100%[===================>]  13.95M  60.2MB/s    in 0.2s    \n",
            "\n",
            "2020-12-19 22:09:13 (60.2 MB/s) - ‘ratings_train.txt’ saved [14628807/14628807]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q33PkINy4Q2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b57831-8672-4ddb-f8a0-4469ce8a2536"
      },
      "source": [
        "!head ratings_train.txt\n",
        "!head ratings_test.txt\n",
        "# !head ko_data.csv #별도 kaggle에서 받아서 사용 https://www.kaggle.com/c/korean-sa-competition-bdc101"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id\tdocument\tlabel\n",
            "9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n",
            "3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n",
            "10265843\t너무재밓었다그래서보는것을추천한다\t0\n",
            "9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n",
            "6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1\n",
            "5403919\t막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\t0\n",
            "7797314\t원작의 긴장감을 제대로 살려내지못했다.\t0\n",
            "9443947\t별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네\t0\n",
            "7156791\t액션이 없는데도 재미 있는 몇안되는 영화\t1\n",
            "id\tdocument\tlabel\n",
            "6270596\t굳 ㅋ\t1\n",
            "9274899\tGDNTOPCLASSINTHECLUB\t0\n",
            "8544678\t뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\t0\n",
            "6825595\t지루하지는 않은데 완전 막장임... 돈주고 보기에는....\t0\n",
            "6723715\t3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\t0\n",
            "7898805\t음악이 주가 된, 최고의 음악영화\t1\n",
            "6315043\t진정한 쓰레기\t0\n",
            "6097171\t마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터가,고개를 젖게한다\t0\n",
            "8932678\t갈수록 개판되가는 중국영화 유치하고 내용없음 폼잡다 끝남 말도안되는 무기에 유치한cg남무 아 그립다 동사서독같은 영화가 이건 3류아류작이다\t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlcJNrwpmMGf"
      },
      "source": [
        "# 필요 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iFVHYMAwQUt"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, ElectraTokenizer, ElectraForSequenceClassification, AdamW\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrJxirH4dJ3-"
      },
      "source": [
        "# (미사용) TPU 사용을 위해 필요\r\n",
        "#import torch_xla\r\n",
        "#import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e960PwpHtb58"
      },
      "source": [
        "import kss\r\n",
        "import re\r\n",
        "from soynlp.normalizer import *"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i7pg7DaGsxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3902b6aa-77f7-46bc-8158-11a9ef466fb5"
      },
      "source": [
        "# GPU or CPU\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print('No GPU available, using the CPU instead.')\n",
        "\n",
        "# (미사용) TPU\n",
        "#device = xm.xla_device()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq91g3bGwfeV"
      },
      "source": [
        "# 데이터셋 처리 (Dataset Calss / 전처리)\r\n",
        "(train data와 과제 sample data형식이 다르고, encoding이 다르기 때문에 분리 처리)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZKIQNjZwdn1"
      },
      "source": [
        "class NSMC_Dataset(Dataset):\n",
        "  \n",
        "  def __init__(self, csv_file, ftype):\n",
        "    # train data와 sample data 각각 처리\n",
        "\n",
        "    # 초기 전처리 1, 아래쪽 전처리 2 로 clean_text() 펑션 분리함 (학습 할때 line별 전처리 후 사용됨)\n",
        "    # --- 전처리 1 start ------------------------\n",
        "\n",
        "    if ftype == 'train':\n",
        "      # 일부 값중에 NaN 제거\n",
        "      self.dataset = pd.read_csv(csv_file, sep='\\t').dropna(axis=0)\n",
        "\n",
        "    elif ftype == 'sample':\n",
        "      # 한글처리용 cp949적용\n",
        "      self.dataset = pd.read_csv(csv_file, sep=',', encoding='cp949') \n",
        "       # 뒤쪽 컬럼 label 값이 없으므로 기본값으로 추가함\n",
        "      self.dataset.insert(2,'Predicted','-')\n",
        "      #print(self.dataset)\n",
        "    else:\n",
        "      self.dataset = pd.read_csv(csv_file, sep=',').dropna(axis=0)\n",
        "\n",
        "\n",
        "    # for idx, document in self.dataset.iterrows():\n",
        "    #   print(idx, document)\n",
        "    self.sub1 = re.compile('[^ .?!/@$%~|0-9|ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기, 특수기호 일부를 제외한 모든 글자제거\n",
        "    self.sub2 = re.compile('[\\s]+')  # white space duplicate\n",
        "    self.sub3 = re.compile('[\\.]+')  # full stop duplicate\n",
        "\n",
        "    #중복되는 문장 제거\n",
        "    if ftype == 'sample':\n",
        "      print('과제 제출용은 중복 문장 제거하면 안됨')\n",
        "    else:\n",
        "      # 중복제거: document가 리뷰 텍스트 내용의 title명이다\n",
        "      self.dataset.drop_duplicates(subset=['document'], inplace=True)\n",
        "\n",
        "    # dataset 확인\n",
        "    print(self.dataset.describe())\n",
        "    print(self.dataset)\n",
        "\n",
        "    # tokenizer\n",
        "    #self.tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-small-v3-discriminator\")\n",
        "    self.tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
        "    \n",
        "    # --- 전처리 1 end ------------------------\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "  \n",
        "  def clean_text(self, txt):\n",
        "    # --- 전처리 2 start ----------------------\n",
        "    cleaned = self.sub1.sub('', txt.strip())  # .strip()은 문장의 앞뒤 공백제거함\n",
        "    cleaned = self.sub2.sub(' ', cleaned)\n",
        "    cleaned = self.sub3.sub('.', cleaned)\n",
        "    #cleaned = emoticon_normalize(cleaned, num_repeats=3) # 감정 반복 단순화\n",
        "    #cleaned = repeat_normalize(cleaned, num_repeats=2) # 중복 글자 단순화\n",
        "    #cleaned = only_text(cleaned) # text만 추출\n",
        "    #cleaned = only_hangle(cleaned) # 한글만 추출\n",
        "    #cleaned = only_hangle_number(cleaned) # 한글/숫자만 추출\n",
        "\n",
        "    # 문장 분리하여 일정 길이 넘는 것만 사용\n",
        "    ttStr = \"\"\n",
        "    for ssStr in kss.split_sentences(cleaned):\n",
        "      #print(ssStr)\n",
        "      if len(ssStr) > 1:\n",
        "        #ttStr += ssStr + \" \\n\"\n",
        "        ttStr += \"[CLS] \" + ssStr + \" [SEP]\"\n",
        "\n",
        "    cleaned = ttStr\n",
        "    # --- 전처리 2 end ------------------------\n",
        "    return cleaned\n",
        "\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    # 행번호별 컬럼 지정하여 할당\n",
        "    row = self.dataset.iloc[idx, 1:3].values  # idx번째 행의 첫번째 컬럼 0을 제외하고 1~3컬럼 할당\n",
        "    text = self.clean_text( txt=row[0] ) # 전처리 2 : clean_text()\n",
        "    y = row[1]\n",
        "\n",
        "    inputs = self.tokenizer(\n",
        "        text, \n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        pad_to_max_length=True,\n",
        "        add_special_tokens=True\n",
        "        )\n",
        "    \n",
        "    input_ids = inputs['input_ids'][0]\n",
        "    attention_mask = inputs['attention_mask'][0]\n",
        "\n",
        "    return input_ids, attention_mask, y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESSNkTcXwfUe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2382432b8d33438891e022ac5643c8cb",
            "15f9c5e074ba42249b8d962eafc10192",
            "01c823605d0446648429b25afbf72136",
            "3982936c3b9b41c8a13b257a698bee9e",
            "6ca3142c393646f185e3ffe4acb32d17",
            "745c3d56801143aa98675d7974c970d9",
            "165691f1510e45b2a92de59ef207bdac",
            "01e46f5209764d8798f5e0ef4fa35e4f",
            "db60288eabbc495f81964904c68e8121",
            "022e14bb64354b9b80f1b9fcfdf136ae",
            "c3571445f1d4499696bbcf2c0c3e0797",
            "0a4614f43fcc4e6cbaf38ebf5b2d8b34",
            "806bda4ca36249f683e1df7919533bbd",
            "9351ac08f12343cd8956eab711c35077",
            "bce9faadd42e48b9bee69560538a6ecf",
            "a72a186fb1d54a818fa4f037d5ef852d"
          ]
        },
        "outputId": "6c2728e0-2e5c-4497-cc8a-ec556d68ab22"
      },
      "source": [
        "train_dataset = NSMC_Dataset(\"ratings_train.txt\",\"train\")\n",
        "test_dataset = NSMC_Dataset(\"ratings_test.txt\",\"train\")\n",
        "sample_dataset = NSMC_Dataset(\"ko_data.csv\",\"sample\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 id          label\n",
            "count  1.461820e+05  146182.000000\n",
            "mean   6.779186e+06       0.498283\n",
            "std    2.919223e+06       0.499999\n",
            "min    3.300000e+01       0.000000\n",
            "25%    4.814832e+06       0.000000\n",
            "50%    7.581160e+06       0.000000\n",
            "75%    9.274760e+06       1.000000\n",
            "max    1.027815e+07       1.000000\n",
            "              id                                           document  label\n",
            "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
            "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
            "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
            "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
            "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
            "...          ...                                                ...    ...\n",
            "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
            "149996   8549745                                      평점이 너무 낮아서...      1\n",
            "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
            "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
            "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
            "\n",
            "[146182 rows x 3 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2382432b8d33438891e022ac5643c8cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263326.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db60288eabbc495f81964904c68e8121",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=61.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                 id         label\n",
            "count  4.915700e+04  49157.000000\n",
            "mean   6.752945e+06      0.502695\n",
            "std    2.937158e+06      0.499998\n",
            "min    6.010000e+02      0.000000\n",
            "25%    4.777143e+06      0.000000\n",
            "50%    7.565415e+06      1.000000\n",
            "75%    9.260204e+06      1.000000\n",
            "max    1.027809e+07      1.000000\n",
            "            id                                           document  label\n",
            "0      6270596                                                굳 ㅋ      1\n",
            "1      9274899                               GDNTOPCLASSINTHECLUB      0\n",
            "2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
            "3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
            "4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
            "...        ...                                                ...    ...\n",
            "49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
            "49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
            "49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
            "49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
            "49999  6070594                                         마무리는 또 왜이래      0\n",
            "\n",
            "[49157 rows x 3 columns]\n",
            "과제 제출용은 중복 문장 제거하면 안됨\n",
            "                 Id\n",
            "count  11187.000000\n",
            "mean    5593.000000\n",
            "std     3229.553065\n",
            "min        0.000000\n",
            "25%     2796.500000\n",
            "50%     5593.000000\n",
            "75%     8389.500000\n",
            "max    11186.000000\n",
            "          Id                                           Sentence Predicted\n",
            "0          0                                   정말 많이 울었던 영화입니다.         -\n",
            "1          1                                           시간 낭비예요.         -\n",
            "2          2             포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.         -\n",
            "3          3               지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!         -\n",
            "4          4                          이걸 영화로 만드는 거야?얼마나 가는지 보자.         -\n",
            "...      ...                                                ...       ...\n",
            "11182  11182  이 영화를 커플에게 추천합니다. 영화관에 가다보면 평생 잊지 못할 추억이 하나 생길...         -\n",
            "11183  11183                                     심심__ 그냥 한효주 cf         -\n",
            "11184  11184  공감해서 눈물나는 영화. 안 보신분들이 전부 제가 울었다고 하면 의아해하실텐데 보면...         -\n",
            "11185  11185                                      오토바이 신은 최고네요.         -\n",
            "11186  11186                                   개병헌 쓰면 엉망이 된다ㅋㅋㅋ         -\n",
            "\n",
            "[11187 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO-f3W7bLhWh",
        "outputId": "4781717f-4eaf-4dd0-9662-966dba66277c"
      },
      "source": [
        "tmpstr = '훌륭하다. 초한지 얼른 읽어보고 다시 봐야겠다. 연출 훌륭하다 껄껄 한신의 토사구팽은 슬펐다'\r\n",
        "print( train_dataset.clean_text( txt = tmpstr) )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 훌륭하다. [SEP][CLS] 초한지 얼른 읽어보고 다시 봐야겠다. [SEP][CLS] 연출 훌륭하다 [SEP][CLS] 껄껄 한신의 토사구팽은 슬펐다 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJiAJPUDz40W"
      },
      "source": [
        "# 모델 생성 (Create Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-jRPQXz2r5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4677dbd810db496290ee678121f27e64",
            "889ae85fd6ef4a5cbdd6b7b3c97282d2",
            "b831611028c84ae58aeb8452a1ec3cd4",
            "ed38334e4f364efd87b02794fc88fde9",
            "387493a93a13402b968b58b30524b831",
            "28673908e6ae408c8aa17e8f6aecee0b",
            "0f23ee0740184754b12cdad37299487b",
            "b4c15ba2ba2a4baea1e411eba1d7438a",
            "dbf18e171f3942958114ff90fbf18390",
            "ea15e7924ac44b028e3276d5eeca03e5",
            "c6d672432a044d12ad06f74dc6abc05b",
            "e472dfe07d224634a39f6df6748ed6fe",
            "87c805a1db7c40b0a0700d1641448f6d",
            "bd5c27139e39448fb633cfce68094f5a",
            "08de05aa296744218e4d895d8f264bb4",
            "0cba89c2e47948d5b873c210571d9b73"
          ]
        },
        "outputId": "42d2a5c4-3d73-4ab6-a46e-8c94f3b09c11"
      },
      "source": [
        "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\").to(device)\n",
        "model.cuda()\n",
        "\n",
        "# 한번 실행해보기\n",
        "#text, attention_mask, y = train_dataset[0]\n",
        "#model(text.unsqueeze(0).to(device), attention_mask=attention_mask.unsqueeze(0).to(device))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4677dbd810db496290ee678121f27e64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbf18e171f3942958114ff90fbf18390",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=451776329.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edb0aIFaXr4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5073ad1-8614-4f15-cd12-b5f499f85e33"
      },
      "source": [
        "try:\r\n",
        "  model.load_state_dict(torch.load(\"model.pt\"))\r\n",
        "except:\r\n",
        "  print(\"error - model.load_state_dict(torch.load('model.pt'))\")\r\n",
        "else:\r\n",
        "  print(\"success - model.load_state_dict(torch.load('model.pt'))\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error - model.load_state_dict(torch.load('model.pt'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp6x4GHtz46u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0932c2b-70e7-44cc-dcde-f20e96624925"
      },
      "source": [
        "# 모델 레이어 보기\n",
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmou0LFl0R_X"
      },
      "source": [
        "# 학습(Learn) 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NpXwESN0Q4h"
      },
      "source": [
        "# koelectra-small-v3-discriminator\n",
        "#epochs = 16\n",
        "#batch_size = 128\n",
        "\n",
        "# koelectra-base-v3-discriminator\n",
        "epochs = 4\n",
        "batch_size = 64"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzxoo4H274J"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), \n",
        "                  lr=1e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                  )\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-BRNeE226HH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "2f4aed0f5a744403a955efe7902c9683"
          ]
        },
        "outputId": "3559ac76-ae04-4206-c4d9-73e4f228126a"
      },
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "# 그래디언트 초기화\n",
        "# model.zero_grad()\n",
        "\n",
        "for i in range(epochs):\n",
        "  total_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  batches = 0\n",
        "\n",
        "  # 훈련모드로 변경\n",
        "  model.train()\n",
        "\n",
        "  for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    y_batch = y_batch.to(device)\n",
        "    y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "    loss = F.cross_entropy(y_pred, y_batch)\n",
        "    loss.backward() # Backward 수행으로 그래디언트 계산\n",
        "    #xm.optimizer_step(optimizer, barrier=True)  # TPU 사용시 코드\n",
        "    optimizer.step() # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "    #model.zero_grad() # 그래디언트 초기화\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    correct += (predicted == y_batch).sum()\n",
        "    total += len(y_batch)\n",
        "\n",
        "    batches += 1\n",
        "    if batches % 100 == 0:\n",
        "      print(\"Batch Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
        "  \n",
        "  losses.append(total_loss)\n",
        "  accuracies.append(correct.float() / total)\n",
        "  print(\"Train Loss:\", total_loss, \"Accuracy:\", correct.float() / total)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f4aed0f5a744403a955efe7902c9683",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4569.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch Loss: 57.99291121959686 Accuracy: tensor(0.7188, device='cuda:0')\n",
            "Batch Loss: 99.19672913849354 Accuracy: tensor(0.7706, device='cuda:0')\n",
            "Batch Loss: 135.12257733941078 Accuracy: tensor(0.7976, device='cuda:0')\n",
            "Batch Loss: 168.7762926518917 Accuracy: tensor(0.8135, device='cuda:0')\n",
            "Batch Loss: 200.87471675872803 Accuracy: tensor(0.8234, device='cuda:0')\n",
            "Batch Loss: 230.67249454557896 Accuracy: tensor(0.8317, device='cuda:0')\n",
            "Batch Loss: 262.0344918817282 Accuracy: tensor(0.8374, device='cuda:0')\n",
            "Batch Loss: 291.2737620398402 Accuracy: tensor(0.8426, device='cuda:0')\n",
            "Batch Loss: 319.83797772973776 Accuracy: tensor(0.8468, device='cuda:0')\n",
            "Batch Loss: 346.8082839772105 Accuracy: tensor(0.8508, device='cuda:0')\n",
            "Batch Loss: 377.05677235871553 Accuracy: tensor(0.8523, device='cuda:0')\n",
            "Batch Loss: 406.2782014682889 Accuracy: tensor(0.8547, device='cuda:0')\n",
            "Batch Loss: 436.0415088310838 Accuracy: tensor(0.8561, device='cuda:0')\n",
            "Batch Loss: 463.6447439491749 Accuracy: tensor(0.8586, device='cuda:0')\n",
            "Batch Loss: 491.9301555007696 Accuracy: tensor(0.8602, device='cuda:0')\n",
            "Batch Loss: 518.7619223669171 Accuracy: tensor(0.8625, device='cuda:0')\n",
            "Batch Loss: 545.1898755356669 Accuracy: tensor(0.8636, device='cuda:0')\n",
            "Batch Loss: 571.9681362882257 Accuracy: tensor(0.8649, device='cuda:0')\n",
            "Batch Loss: 600.9905030652881 Accuracy: tensor(0.8654, device='cuda:0')\n",
            "Batch Loss: 628.3732468262315 Accuracy: tensor(0.8664, device='cuda:0')\n",
            "Batch Loss: 654.9117186143994 Accuracy: tensor(0.8671, device='cuda:0')\n",
            "Batch Loss: 680.5261714458466 Accuracy: tensor(0.8681, device='cuda:0')\n",
            "Batch Loss: 706.8076373562217 Accuracy: tensor(0.8691, device='cuda:0')\n",
            "Batch Loss: 733.4812432043254 Accuracy: tensor(0.8701, device='cuda:0')\n",
            "Batch Loss: 760.0207377560437 Accuracy: tensor(0.8709, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8a411af8e272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_masks_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#xm.optimizer_step(optimizer, barrier=True)  # TPU 사용시 코드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQK4R6n4JgVU"
      },
      "source": [
        "losses, accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvEB8g7IFbsD"
      },
      "source": [
        "# 테스트 데이터셋 정확도 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QiALUqm4juf"
      },
      "source": [
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
        "  y_batch = y_batch.to(device)\n",
        "  y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "  _, predicted = torch.max(y_pred, 1)\n",
        "  test_correct += (predicted == y_batch).sum()\n",
        "  test_total += len(y_batch)\n",
        "\n",
        "print(\"Accuracy:\", test_correct.float() / test_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx2HslxKlbk_"
      },
      "source": [
        "# 모델 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrcPWEa5U8JZ"
      },
      "source": [
        "# 모델 저장하기\n",
        "torch.save(model.state_dict(), \"model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiZgwE-VleG4"
      },
      "source": [
        "# 과제용 데이터 예측 및 맵핑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK4PsiNrh089"
      },
      "source": [
        "#과제용 데이터 예측\r\n",
        "# 데이터 로딩\r\n",
        "batchSize = 16\r\n",
        "sample_loader = DataLoader(sample_dataset, batch_size=batchSize, shuffle=False)\r\n",
        "\r\n",
        "sample_result = sample_dataset.dataset.copy(deep=True)\r\n",
        "print(sample_result)\r\n",
        "\r\n",
        "#평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "idx_s = 0\r\n",
        "idx_e = 0\r\n",
        "\r\n",
        "for input_ids_batch, attention_masks_batch, y_batch in tqdm(sample_loader):\r\n",
        "  #y_batch = y_batch.to(device)\r\n",
        "  y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\r\n",
        "  _, predicted = torch.max(y_pred, 1)\r\n",
        "\r\n",
        "  rsList = list(map(int, predicted)) # 결과를 한번에 저장하기 위해 LIST로 변환 처리\r\n",
        "  global idx_s, idx_e\r\n",
        "  idx_e += len(rsList) #해당 배치구간내에 index 끝값 계산\r\n",
        "  #print(\"index==\", idx_s, idx_e)\r\n",
        "  #print(\"--start-- sample_result['predict_label'][idx_s : idx_e]==\\n\" , sample_result['predict_label'][idx_s : idx_e] )\r\n",
        "  sample_result['Predicted'][idx_s : idx_e] = rsList  #배치구간을 한번에 업데이트\r\n",
        "  #print(\"--end-- sample_result['predict_label'][idx_s : idx_e]==\\n\" , sample_result['predict_label'][idx_s : idx_e] )\r\n",
        "  idx_s += len(rsList) #해당 배치구간내에 index 시작값은 윗줄 처리 후 증가\r\n",
        "\r\n",
        "  #test_correct += (predicted == y_batch).sum()\r\n",
        "  #test_total += len(y_batch)\r\n",
        "\r\n",
        "# print(\"Accuracy:\", test_correct.float() / test_total)\r\n",
        "print(sample_result)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UuBA5hRpScv"
      },
      "source": [
        "torch.cuda.empty_cache() #GPU 캐쉬 데이터 삭제"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZe_mZqqTl80"
      },
      "source": [
        "# 결과 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF5PqoUNF92f"
      },
      "source": [
        "# 주어진 데이터의 결과를 파일로 저장\r\n",
        "#sample_csv = sample_result.to_csv('sample.csv')\r\n",
        "sample_csv = sample_result.to_csv('sample.csv',sep=',',na_rep='NaN', columns=['Id','Predicted'],index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cid0Vzi_SFSO"
      },
      "source": [
        "# 파일을 PC로 다운로드 하기\r\n",
        "from google.colab import files\r\n",
        "files.download('sample.csv')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}